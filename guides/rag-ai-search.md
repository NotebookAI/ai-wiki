---
layout: default
title: RAG / AI 搜索专题指南
description: 用读者视角理解 RAG 与 AI 搜索：它们是什么、适合解决什么问题、引用为什么重要，以及如何快速判断一个系统靠不靠谱。
permalink: /guides/rag/
---

<section class="about-page" markdown="1">

当你在用 AI 搜索/答案引擎时，最重要的是：**知道它在做什么、哪里容易出错、怎么判断结果是否可信**。

## 先记住三句话
- **RAG 的本质**：先找“证据”，再写“答案”。它不是让模型更聪明，而是让答案更有来源。  
- **AI 搜索的核心体验**：你看到的不只是结论，而是“结论 + 引用 + 可追溯证据”。  
- **最大风险**：模型能把错误说得很像真的，所以“有没有引用、引用对不对”很关键。

## RAG 是什么？（一个类比）
把 RAG 想成“带资料的开卷考试”：
1. 你先去书里翻到相关段落（检索）
2. 再根据这些段落写出回答（生成）
3. 最好把引用的页码/段落一起写出来（引用/grounding）

对应站内词条（想深入再点）：
- [RAG]({{ '/terms/rag/' | relative_url }})、[AI 搜索]({{ '/terms/ai-search/' | relative_url }})、[Grounding]({{ '/terms/grounding/' | relative_url }})
- [文档分块（Chunking）]({{ '/terms/chunking/' | relative_url }})、[Retriever]({{ '/terms/retriever/' | relative_url }})、[Reranker]({{ '/terms/reranker/' | relative_url }})

## 什么时候应该用 RAG / AI 搜索？
适合：
- 你关心的是**最新**或**特定领域**的信息（产品文档、内部知识库、政策条款等）
- 你需要“答案可追溯”，能把结论指回具体来源

不一定适合：
- 纯创作、脑洞类任务（不依赖外部证据）
- 来源本身就不可靠/无法授权/无法索引的内容

## 为什么“引用”比“回答像不像”更重要？
因为“像真的”不等于“是真的”。一个好的答案引擎，至少要做到：
- 能告诉你它依据哪段材料得出结论（引用）
- 引用能被你点开核验（可追溯）
- 证据不足时敢说“不确定/缺证据”（诚实）

你可以用这三个问题快速验收：
1. **它引用了吗？**（有没有来源）
2. **引用对齐吗？**（来源里真的支持这句话吗）
3. **引用够具体吗？**（能定位到段落/片段，而不是只给整篇链接）

## 读者最常见的误区
- **“有引用就可靠”**：不一定，引用可能是装饰性的，甚至和结论无关。
- **“换更大模型就行”**：很多时候问题在检索没找对证据，而不是模型不够大。
- **“RAG 能消灭幻觉”**：它只能降低风险；如果证据错/缺，幻觉依然会发生。

## 一个“好用”的 AI 搜索回答长什么样？
通常会更像：
- 先给你 3–7 条要点结论
- 每条结论后面带引用（可点开）
- 复杂问题会先问你一个澄清问题（比如范围、版本、时间）
而不是：
- 一大段流畅长文，没有可核验来源
- 引用很多，但点开都对不上

## 想更进一步：RAG 评测怎么理解？
把评测想成“你能不能长期信任它”，主要看三层：
- **检索层**：证据找得对不对、全不全
- **生成层**：回答有没有忠于证据、有没有胡编
- **端到端**：在真实任务里是否更省时间、少踩坑

更完整的读者版清单在这里：
- [RAG 评测与回归]({{ '/guides/rag-evaluation/' | relative_url }})

## 继续阅读
- 词条： [RAG]({{ '/terms/rag/' | relative_url }})、[AI 搜索]({{ '/terms/ai-search/' | relative_url }})、[RAG 评测]({{ '/terms/rag-evaluation/' | relative_url }})
- 专题： [RAG 评测与回归]({{ '/guides/rag-evaluation/' | relative_url }})

## 参考资料（入门即可）
- [Lewis et al. “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.” (2020)](https://arxiv.org/abs/2005.11401)
- [Asai et al. “Self-RAG.” (2023)](https://arxiv.org/abs/2310.11511)

</section>
