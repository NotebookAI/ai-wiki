---
id: bias
title: 偏见（Bias）
title_en: Bias
category: safety
type: concept
order: 76
aliases: [偏见, Algorithmic Bias]
keywords: [Bias, 偏见, 公平性, 数据偏差]
brief: 指由于数据、模型或系统设计导致的系统性不公平或失真现象，在 AI 应用中是重要的风险来源。
meta: [公平性, 数据治理]
---

偏见可能源于训练数据中的不平衡或刻板印象，也可能来自目标函数和系统设计（例如只追求点击率）。在大模型中，偏见会体现在对不同性别、种族、地域、职业等群体的描述与决策上，进而影响招聘、信贷、司法等敏感领域的应用。

缓解偏见需要结合数据审计、对抗训练、后处理校准和人类监督等多种手段，并在产品层面提供反馈渠道与纠错机制。

