---
id: ai-safety
title: AI Safety（人工智能安全）
title_en: AI Safety
category: safety
type: concept
order: 74
aliases: [AI Safety, 人工智能安全]
keywords: [AI Safety, 人工智能安全, 风险治理, 责任 AI]
brief: 研究和实践如何让 AI 系统在行为、影响和长期演化上保持对人类有益且可控的跨学科领域。
meta: [风险治理, 责任 AI]
---

AI Safety 关注的问题包括：模型是否会输出有害内容、是否会被越狱滥用、是否存在提示注入与越权工具调用风险、是否在决策中造成系统性偏见，以及在长期尺度上是否可能对社会和人类构成结构性风险。它涵盖技术、政策、伦理和治理等多方面。

在大模型落地中，AI Safety 通常体现在红队测试、安全基线、内容过滤、审计日志、Guardrails（防护栏）和事故响应机制等工程实践上：
- [红队测试]({{ '/terms/red-teaming/' | relative_url }})
- [Guardrails]({{ '/terms/guardrails/' | relative_url }})
- [提示注入]({{ '/terms/prompt-injection/' | relative_url }})
- [越狱]({{ '/terms/jailbreak/' | relative_url }})
