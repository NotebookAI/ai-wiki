---
id: mt-bench
title: MT-Bench 对话评测
title_en: MT-Bench
category: safety
type: concept
order: 79
aliases: [MT-Bench]
keywords: [MT-Bench, Chatbot 评测, LMSYS, Arena]
brief: 由 LMSYS 提出的多轮对话评测基准，关注模型在开放式问答和对话任务中的综合表现。
meta: [对话评估, 多轮问答]
---

MT-Bench 通过一组多轮对话问题，覆盖编码、数学、推理、知识问答等多个维度，并通常使用更强的模型（如 GPT-4）作为「评审」对候选回答进行打分。它与 LMSYS Arena 等人类偏好评测一起，构成了当前对话型大模型评估的重要参考。

与传统单轮问答基准相比，MT-Bench 更接近真实使用场景，有助于发现模型在对话连贯性、指令遵循与安全性方面的问题。

