---
id: jailbreak
title: 越狱（Jailbreak）
title_en: Jailbreak
category: safety
type: concept
order: 87
aliases: [Jailbreak, 越狱提示, 破防]
keywords: [Jailbreak, 越狱, Safety, 规则绕过, 诱导]
brief: 通过特定提示或对话策略绕过模型安全规则/拒答策略，让模型输出原本应被禁止的内容或行为的攻击/对抗方式。
meta: [对抗提示, 安全风险]
---

越狱（Jailbreak）指攻击者利用提示技巧、角色扮演、分步诱导、编码绕过等方法，让模型绕过安全策略（例如拒答规则、内容过滤、工具权限限制），从而生成有害内容或执行不当行动。

### 与“提示注入”的区别
- 越狱更偏“**绕过模型的安全对齐与拒答**”（让模型说本不该说的话）。
- 提示注入更偏“**劫持模型的任务目标或权限边界**”（让模型做本不该做的事，尤其在 Agent/工具调用场景）。

实践中两者常同时出现：越狱让模型愿意配合，注入让模型按攻击者目标行动。

### 常见形式
- **角色扮演/多重人格**：诱导模型进入“无规则模式”。
- **分步拆解**：把敏感请求拆成看似无害的多步问题。
- **编码与变体**：使用谐音、拼写扰动、base64/rot13 等绕过关键词过滤。

### 应对思路
- **红队测试与回归集**：把已知越狱样例固化为测试用例，持续回归。
- **分层防护**：模型侧策略 + 规则/分类器 + 人工审核（高风险场景）。
- **安全边界外置**：不要把“模型拒答”当作唯一安全机制，关键动作需要权限与审计兜底。

### 相关词条
- {{ '/terms/prompt-injection/' | relative_url }}、{{ '/terms/ai-safety/' | relative_url }}、{{ '/terms/red-teaming/' | relative_url }}

